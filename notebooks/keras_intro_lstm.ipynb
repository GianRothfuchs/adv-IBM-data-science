{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Keras Intro\n\nThe following notebook shows the basic steps required to run a model in Keras. The example is functional but but contains some data pre- and post-processing.\n\nTo install TensorFlow and Keras the following items are required:\n\n```python\npip install tensorflow \npip install h5py graphviz pydot\npip install keras\n```"}, {"metadata": {}, "cell_type": "code", "source": "from keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.optimizers import SGD\nfrom keras.utils import to_categorical\n\n\nfrom keras.datasets import imdb", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Using TensorFlow backend.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "max_features = 20000 # choosing the 20000 most common words from the vocab\nmaxlen = 80          # only sequences of lenght 80 are allowed, this restricts to short texts", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# 0.1 Load data\n(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=max_features)", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# 0.2 Pre-processing (padding/cropping to len=80)\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test  = sequence.pad_sequences(x_test , maxlen=maxlen)\n\n", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# 1. Model Instantiation\nmodel = Sequential()\n", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# 2. Adding layers\nmodel.add(Embedding(max_features,128))\nmodel.add(LSTM(128, dropout=1-0.2, recurrent_dropout=-10.2))\nmodel.add(Dense(1, activation='sigmoid')) # 0 bad, 1 good\n", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# 3. Compile model\nmodel.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])\n", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# 4. Fit model\nmodel.fit(x_train,y_train, batch_size=32, epochs=10,validation_data=(x_test,y_test))\n", "execution_count": null, "outputs": [{"output_type": "stream", "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 25000 samples, validate on 25000 samples\nEpoch 1/10\n 5696/25000 [=====>........................] - ETA: 8:59 - loss: 0.6932 - acc: 0.5053", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model.evaluate(x_test,y_test,batch_size=32)", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}